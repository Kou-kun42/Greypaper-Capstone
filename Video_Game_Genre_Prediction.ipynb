{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Video Game Genre Prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import utils\n",
    "\n",
    "import os, PIL\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\"\"\" Sequential Model Architecture \"\"\"\n",
    "Sequential = tf.keras.models.Sequential\n",
    "\n",
    "\"\"\" Data Preprocessing Functions \"\"\"\n",
    "Resizing = tf.keras.layers.experimental.preprocessing.Resizing\n",
    "Rescaling = tf.keras.layers.experimental.preprocessing.Rescaling\n",
    "\n",
    "\"\"\" Data Augmentation Functions \"\"\"\n",
    "RandomFlip = tf.keras.layers.experimental.preprocessing.RandomFlip\n",
    "RandomRotation = tf.keras.layers.experimental.preprocessing.RandomRotation\n",
    "RandomZoom = tf.keras.layers.experimental.preprocessing.RandomZoom\n",
    "\n",
    "\"\"\" Artificial Neural Network Layer Inventory \"\"\"\n",
    "Dense = tf.keras.layers.Dense\n",
    "Dropout = tf.keras.layers.Dropout\n",
    "\n",
    "\"\"\" Convolutional Neural Network Layer Inventory \"\"\"\n",
    "Conv2D = tf.keras.layers.Conv2D\n",
    "MaxPool2D = tf.keras.layers.MaxPool2D\n",
    "Flatten = tf.keras.layers.Flatten\n",
    "\n",
    "\"\"\" Residual Network Layer Inventory \"\"\"\n",
    "ResNet50 = tf.keras.applications.resnet50.ResNet50\n",
    "\n",
    "\"\"\" Function to Load Images from Target Folder \"\"\"\n",
    "image_dataset_from_directory = tf.keras.preprocessing.image_dataset_from_directory"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "DATA_DIRECTORY = \"dataset/\"\n",
    "FIGHTING_GENRE_COVERS = f\"{DATA_DIRECTORY}/fighting/*\"\n",
    "INDIE_GENRE_COVERS = f\"{DATA_DIRECTORY}/indie/*\"\n",
    "PLATFORM_GENRE_COVERS = f\"{DATA_DIRECTORY}/platform/*\"\n",
    "PUZZLE_GENRE_COVERS = f\"{DATA_DIRECTORY}/puzzle/*\"\n",
    "SPORT_GENRE_COVERS = f\"{DATA_DIRECTORY}/indie/*\"\n",
    "\n",
    "print(f\"{len(glob(FIGHTING_GENRE_COVERS))} Fighting Game Covers\")\n",
    "print(f\"{len(glob(INDIE_GENRE_COVERS))} Indie Game Covers\")\n",
    "print(f\"{len(glob(PLATFORM_GENRE_COVERS))} Platform Game Covers\")\n",
    "print(f\"{len(glob(PUZZLE_GENRE_COVERS))} Puzzle Game Covers\")\n",
    "print(f\"{len(glob(SPORT_GENRE_COVERS))} Sport Game Covers\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1000 Fighting Game Covers\n",
      "1000 Indie Game Covers\n",
      "1000 Platform Game Covers\n",
      "1000 Puzzle Game Covers\n",
      "1000 Sport Game Covers\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "batch_size = 32\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "train = image_dataset_from_directory(\n",
    "    directory=DATA_DIRECTORY,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation = image_dataset_from_directory(\n",
    "    directory=DATA_DIRECTORY,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = train.class_names\n",
    "print(class_names)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 5000 files belonging to 5 classes.\n",
      "Using 4000 files for training.\n",
      "Found 5000 files belonging to 5 classes.\n",
      "Using 1000 files for validation.\n",
      "['fighting', 'indie', 'platform', 'puzzle', 'sport']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train = train.cache().shuffle(4000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation = validation.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "input_tensor = tf.keras.Input(shape=(224,224,3))\n",
    "resnet_model = ResNet50(include_top=False, weights=\"resnet50_weights.h5\", input_tensor=input_tensor)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for layer in resnet_model.layers[:143]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i, layer in enumerate(resnet_model.layers):\n",
    "    print(i, layer.name, \"Trainable: \", layer.trainable)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 input_1 Trainable:  False\n",
      "1 conv1_pad Trainable:  False\n",
      "2 conv1_conv Trainable:  False\n",
      "3 conv1_bn Trainable:  False\n",
      "4 conv1_relu Trainable:  False\n",
      "5 pool1_pad Trainable:  False\n",
      "6 pool1_pool Trainable:  False\n",
      "7 conv2_block1_1_conv Trainable:  False\n",
      "8 conv2_block1_1_bn Trainable:  False\n",
      "9 conv2_block1_1_relu Trainable:  False\n",
      "10 conv2_block1_2_conv Trainable:  False\n",
      "11 conv2_block1_2_bn Trainable:  False\n",
      "12 conv2_block1_2_relu Trainable:  False\n",
      "13 conv2_block1_0_conv Trainable:  False\n",
      "14 conv2_block1_3_conv Trainable:  False\n",
      "15 conv2_block1_0_bn Trainable:  False\n",
      "16 conv2_block1_3_bn Trainable:  False\n",
      "17 conv2_block1_add Trainable:  False\n",
      "18 conv2_block1_out Trainable:  False\n",
      "19 conv2_block2_1_conv Trainable:  False\n",
      "20 conv2_block2_1_bn Trainable:  False\n",
      "21 conv2_block2_1_relu Trainable:  False\n",
      "22 conv2_block2_2_conv Trainable:  False\n",
      "23 conv2_block2_2_bn Trainable:  False\n",
      "24 conv2_block2_2_relu Trainable:  False\n",
      "25 conv2_block2_3_conv Trainable:  False\n",
      "26 conv2_block2_3_bn Trainable:  False\n",
      "27 conv2_block2_add Trainable:  False\n",
      "28 conv2_block2_out Trainable:  False\n",
      "29 conv2_block3_1_conv Trainable:  False\n",
      "30 conv2_block3_1_bn Trainable:  False\n",
      "31 conv2_block3_1_relu Trainable:  False\n",
      "32 conv2_block3_2_conv Trainable:  False\n",
      "33 conv2_block3_2_bn Trainable:  False\n",
      "34 conv2_block3_2_relu Trainable:  False\n",
      "35 conv2_block3_3_conv Trainable:  False\n",
      "36 conv2_block3_3_bn Trainable:  False\n",
      "37 conv2_block3_add Trainable:  False\n",
      "38 conv2_block3_out Trainable:  False\n",
      "39 conv3_block1_1_conv Trainable:  False\n",
      "40 conv3_block1_1_bn Trainable:  False\n",
      "41 conv3_block1_1_relu Trainable:  False\n",
      "42 conv3_block1_2_conv Trainable:  False\n",
      "43 conv3_block1_2_bn Trainable:  False\n",
      "44 conv3_block1_2_relu Trainable:  False\n",
      "45 conv3_block1_0_conv Trainable:  False\n",
      "46 conv3_block1_3_conv Trainable:  False\n",
      "47 conv3_block1_0_bn Trainable:  False\n",
      "48 conv3_block1_3_bn Trainable:  False\n",
      "49 conv3_block1_add Trainable:  False\n",
      "50 conv3_block1_out Trainable:  False\n",
      "51 conv3_block2_1_conv Trainable:  False\n",
      "52 conv3_block2_1_bn Trainable:  False\n",
      "53 conv3_block2_1_relu Trainable:  False\n",
      "54 conv3_block2_2_conv Trainable:  False\n",
      "55 conv3_block2_2_bn Trainable:  False\n",
      "56 conv3_block2_2_relu Trainable:  False\n",
      "57 conv3_block2_3_conv Trainable:  False\n",
      "58 conv3_block2_3_bn Trainable:  False\n",
      "59 conv3_block2_add Trainable:  False\n",
      "60 conv3_block2_out Trainable:  False\n",
      "61 conv3_block3_1_conv Trainable:  False\n",
      "62 conv3_block3_1_bn Trainable:  False\n",
      "63 conv3_block3_1_relu Trainable:  False\n",
      "64 conv3_block3_2_conv Trainable:  False\n",
      "65 conv3_block3_2_bn Trainable:  False\n",
      "66 conv3_block3_2_relu Trainable:  False\n",
      "67 conv3_block3_3_conv Trainable:  False\n",
      "68 conv3_block3_3_bn Trainable:  False\n",
      "69 conv3_block3_add Trainable:  False\n",
      "70 conv3_block3_out Trainable:  False\n",
      "71 conv3_block4_1_conv Trainable:  False\n",
      "72 conv3_block4_1_bn Trainable:  False\n",
      "73 conv3_block4_1_relu Trainable:  False\n",
      "74 conv3_block4_2_conv Trainable:  False\n",
      "75 conv3_block4_2_bn Trainable:  False\n",
      "76 conv3_block4_2_relu Trainable:  False\n",
      "77 conv3_block4_3_conv Trainable:  False\n",
      "78 conv3_block4_3_bn Trainable:  False\n",
      "79 conv3_block4_add Trainable:  False\n",
      "80 conv3_block4_out Trainable:  False\n",
      "81 conv4_block1_1_conv Trainable:  False\n",
      "82 conv4_block1_1_bn Trainable:  False\n",
      "83 conv4_block1_1_relu Trainable:  False\n",
      "84 conv4_block1_2_conv Trainable:  False\n",
      "85 conv4_block1_2_bn Trainable:  False\n",
      "86 conv4_block1_2_relu Trainable:  False\n",
      "87 conv4_block1_0_conv Trainable:  False\n",
      "88 conv4_block1_3_conv Trainable:  False\n",
      "89 conv4_block1_0_bn Trainable:  False\n",
      "90 conv4_block1_3_bn Trainable:  False\n",
      "91 conv4_block1_add Trainable:  False\n",
      "92 conv4_block1_out Trainable:  False\n",
      "93 conv4_block2_1_conv Trainable:  False\n",
      "94 conv4_block2_1_bn Trainable:  False\n",
      "95 conv4_block2_1_relu Trainable:  False\n",
      "96 conv4_block2_2_conv Trainable:  False\n",
      "97 conv4_block2_2_bn Trainable:  False\n",
      "98 conv4_block2_2_relu Trainable:  False\n",
      "99 conv4_block2_3_conv Trainable:  False\n",
      "100 conv4_block2_3_bn Trainable:  False\n",
      "101 conv4_block2_add Trainable:  False\n",
      "102 conv4_block2_out Trainable:  False\n",
      "103 conv4_block3_1_conv Trainable:  False\n",
      "104 conv4_block3_1_bn Trainable:  False\n",
      "105 conv4_block3_1_relu Trainable:  False\n",
      "106 conv4_block3_2_conv Trainable:  False\n",
      "107 conv4_block3_2_bn Trainable:  False\n",
      "108 conv4_block3_2_relu Trainable:  False\n",
      "109 conv4_block3_3_conv Trainable:  False\n",
      "110 conv4_block3_3_bn Trainable:  False\n",
      "111 conv4_block3_add Trainable:  False\n",
      "112 conv4_block3_out Trainable:  False\n",
      "113 conv4_block4_1_conv Trainable:  False\n",
      "114 conv4_block4_1_bn Trainable:  False\n",
      "115 conv4_block4_1_relu Trainable:  False\n",
      "116 conv4_block4_2_conv Trainable:  False\n",
      "117 conv4_block4_2_bn Trainable:  False\n",
      "118 conv4_block4_2_relu Trainable:  False\n",
      "119 conv4_block4_3_conv Trainable:  False\n",
      "120 conv4_block4_3_bn Trainable:  False\n",
      "121 conv4_block4_add Trainable:  False\n",
      "122 conv4_block4_out Trainable:  False\n",
      "123 conv4_block5_1_conv Trainable:  False\n",
      "124 conv4_block5_1_bn Trainable:  False\n",
      "125 conv4_block5_1_relu Trainable:  False\n",
      "126 conv4_block5_2_conv Trainable:  False\n",
      "127 conv4_block5_2_bn Trainable:  False\n",
      "128 conv4_block5_2_relu Trainable:  False\n",
      "129 conv4_block5_3_conv Trainable:  False\n",
      "130 conv4_block5_3_bn Trainable:  False\n",
      "131 conv4_block5_add Trainable:  False\n",
      "132 conv4_block5_out Trainable:  False\n",
      "133 conv4_block6_1_conv Trainable:  False\n",
      "134 conv4_block6_1_bn Trainable:  False\n",
      "135 conv4_block6_1_relu Trainable:  False\n",
      "136 conv4_block6_2_conv Trainable:  False\n",
      "137 conv4_block6_2_bn Trainable:  False\n",
      "138 conv4_block6_2_relu Trainable:  False\n",
      "139 conv4_block6_3_conv Trainable:  False\n",
      "140 conv4_block6_3_bn Trainable:  False\n",
      "141 conv4_block6_add Trainable:  False\n",
      "142 conv4_block6_out Trainable:  False\n",
      "143 conv5_block1_1_conv Trainable:  True\n",
      "144 conv5_block1_1_bn Trainable:  True\n",
      "145 conv5_block1_1_relu Trainable:  True\n",
      "146 conv5_block1_2_conv Trainable:  True\n",
      "147 conv5_block1_2_bn Trainable:  True\n",
      "148 conv5_block1_2_relu Trainable:  True\n",
      "149 conv5_block1_0_conv Trainable:  True\n",
      "150 conv5_block1_3_conv Trainable:  True\n",
      "151 conv5_block1_0_bn Trainable:  True\n",
      "152 conv5_block1_3_bn Trainable:  True\n",
      "153 conv5_block1_add Trainable:  True\n",
      "154 conv5_block1_out Trainable:  True\n",
      "155 conv5_block2_1_conv Trainable:  True\n",
      "156 conv5_block2_1_bn Trainable:  True\n",
      "157 conv5_block2_1_relu Trainable:  True\n",
      "158 conv5_block2_2_conv Trainable:  True\n",
      "159 conv5_block2_2_bn Trainable:  True\n",
      "160 conv5_block2_2_relu Trainable:  True\n",
      "161 conv5_block2_3_conv Trainable:  True\n",
      "162 conv5_block2_3_bn Trainable:  True\n",
      "163 conv5_block2_add Trainable:  True\n",
      "164 conv5_block2_out Trainable:  True\n",
      "165 conv5_block3_1_conv Trainable:  True\n",
      "166 conv5_block3_1_bn Trainable:  True\n",
      "167 conv5_block3_1_relu Trainable:  True\n",
      "168 conv5_block3_2_conv Trainable:  True\n",
      "169 conv5_block3_2_bn Trainable:  True\n",
      "170 conv5_block3_2_relu Trainable:  True\n",
      "171 conv5_block3_3_conv Trainable:  True\n",
      "172 conv5_block3_3_bn Trainable:  True\n",
      "173 conv5_block3_add Trainable:  True\n",
      "174 conv5_block3_out Trainable:  True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "resizing_layer = Resizing(IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "normalization_layer = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "input_layer = tf.keras.layers.InputLayer(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "\n",
    "flatten_layer = Flatten()\n",
    "\n",
    "dropout_layer = Dropout(0.5)\n",
    "\n",
    "dense_layer_1 = Dense(256, activation=\"relu\")\n",
    "dense_layer_2 = Dense(128, activation=\"relu\")\n",
    "dense_layer_3 = Dense(64, activation=\"relu\")\n",
    "output_layer = Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(input_layer)\n",
    "model.add(resizing_layer)\n",
    "model.add(resnet_model)\n",
    "model.add(flatten_layer)\n",
    "model.add(normalization_layer)\n",
    "model.add(dense_layer_1)\n",
    "model.add(dropout_layer)\n",
    "model.add(dense_layer_2)\n",
    "model.add(dropout_layer)\n",
    "model.add(dense_layer_3)\n",
    "model.add(dropout_layer)\n",
    "model.add(output_layer)\n",
    "\n",
    "model.summary()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resizing (Resizing)          (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 100352)            401408    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               25690368  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 49,720,705\n",
      "Trainable params: 40,908,289\n",
      "Non-trainable params: 8,812,416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "checkpoint = tf.keras.callbacks(filepath=\"model/genre_model.h5\",\n",
    "                                monitor=\"val_accuracy\",\n",
    "                                mode=\"max\",\n",
    "                                save_best_only=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "history = model.fit(train, validation_data=validation, callbacks=[checkpoint], epochs=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 420s 3s/step - loss: 0.0000e+00 - accuracy: 0.2030 - val_loss: 0.0000e+00 - val_accuracy: 0.1910\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 387s 3s/step - loss: 0.0000e+00 - accuracy: 0.2023 - val_loss: 0.0000e+00 - val_accuracy: 0.1910\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 386s 3s/step - loss: 0.0000e+00 - accuracy: 0.2023 - val_loss: 0.0000e+00 - val_accuracy: 0.1910\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 392s 3s/step - loss: 0.0000e+00 - accuracy: 0.2023 - val_loss: 0.0000e+00 - val_accuracy: 0.1910\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 431s 3s/step - loss: 0.0000e+00 - accuracy: 0.2023 - val_loss: 0.0000e+00 - val_accuracy: 0.1910\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resizing (Resizing)          (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet50 (Functional)        (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 100352)            401408    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               25690368  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 49,720,705\n",
      "Trainable params: 40,908,289\n",
      "Non-trainable params: 8,812,416\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model.evaluate(validation)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "32/32 [==============================] - 60s 2s/step - loss: 0.0000e+00 - accuracy: 0.1910\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.0, 0.19099999964237213]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "model.save(\"model/genre_model.h5\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/kou/dev/courses/acs3520/Fire-Detection-API-Project/env/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "8359fd2a697189406a671944a51afd43ef544a8a0e515d8a5398f7ad047a932a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}